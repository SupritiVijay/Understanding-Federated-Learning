{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torchvision\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T12:03:05.377736Z","iopub.execute_input":"2022-02-28T12:03:05.378090Z","iopub.status.idle":"2022-02-28T12:03:06.892890Z","shell.execute_reply.started":"2022-02-28T12:03:05.377998Z","shell.execute_reply":"2022-02-28T12:03:06.891589Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:03:06.897092Z","iopub.execute_input":"2022-02-28T12:03:06.897368Z","iopub.status.idle":"2022-02-28T12:03:08.380056Z","shell.execute_reply.started":"2022-02-28T12:03:06.897337Z","shell.execute_reply":"2022-02-28T12:03:08.379044Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_train.csv\")\ndata_test = pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_test.csv\")\nfeatures = data_train.columns[data_train.columns != 'label']\ndata_train","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:03:08.381781Z","iopub.execute_input":"2022-02-28T12:03:08.382246Z","iopub.status.idle":"2022-02-28T12:03:14.792936Z","shell.execute_reply.started":"2022-02-28T12:03:08.382213Z","shell.execute_reply":"2022-02-28T12:03:14.792073Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# tsne = TSNE(n_components=2, random_state=1)\n# visualize = tsne.fit_transform(data_train[features])\n\n# plt.figure(figsize = (30,12))\n# plt.subplot(122)\n# plt.scatter(X_reduced[:,0],X_reduced[:,1],  c = df_train[target], \n#             cmap = \"coolwarm\", edgecolor = \"None\", alpha=0.35)\n# plt.colorbar()\n# plt.title('TSNE Scatter Plot')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:03:14.795611Z","iopub.execute_input":"2022-02-28T12:03:14.796250Z","iopub.status.idle":"2022-02-28T12:03:14.801119Z","shell.execute_reply.started":"2022-02-28T12:03:14.796202Z","shell.execute_reply":"2022-02-28T12:03:14.800163Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"input_size = 784\nepochs = 10\nhidden_layers=500\nnum_classes = 10\nbatch_size = 100\nlearning_rate = 0.001 ","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:03:14.802805Z","iopub.execute_input":"2022-02-28T12:03:14.803541Z","iopub.status.idle":"2022-02-28T12:03:14.815053Z","shell.execute_reply.started":"2022-02-28T12:03:14.803494Z","shell.execute_reply":"2022-02-28T12:03:14.814072Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class NeuralNetwork(nn.Module):\n    def __init__(self, input_size, hidden_layers, num_classes):\n        super(NeuralNetwork, self).__init__()\n        self.input_size = input_size\n        self.l1= nn.Linear(input_size, hidden_layers)\n        self.relu = nn.ReLU()\n        self.l2 = nn.Linear(hidden_layers, num_classes)  \n        \n    def forward(self, x):\n        out = self.l1(x)\n        out = self.relu(out)\n        out = self.l2(out)\n        return out \n\nmodel = NeuralNetwork(input_size, hidden_layers, num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:03:14.816571Z","iopub.execute_input":"2022-02-28T12:03:14.816938Z","iopub.status.idle":"2022-02-28T12:03:14.856811Z","shell.execute_reply.started":"2022-02-28T12:03:14.816894Z","shell.execute_reply":"2022-02-28T12:03:14.855630Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def training_model(training_set, model, epochs, testing_set):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n    total_steps = len(training_set)\n    \n    for epoch in range(epochs):\n        for i in range(0, len(training_set), batch_size):\n            images_batch = training_set[features][i:i+batch_size]\n            images_batch = torch.from_numpy(np.array(images_batch)).float()\n            labels_batch = training_set.label[i:i+batch_size]\n            labels_batch = torch.from_numpy(np.array(labels_batch))\n            \n            # Forward propogation\n            outputs = model(images_batch)\n            loss = criterion(outputs, labels_batch)\n            \n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step() \n            \n        \n        print (f'Epoch [{epoch+1}/{epochs}], Step[{i+1}/{total_steps}], Loss: {loss.item():.4f}')\n        testing_model(model, testing_set)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:04:56.213849Z","iopub.execute_input":"2022-02-28T12:04:56.214355Z","iopub.status.idle":"2022-02-28T12:04:56.223045Z","shell.execute_reply.started":"2022-02-28T12:04:56.214307Z","shell.execute_reply":"2022-02-28T12:04:56.222425Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def testing_model(model, training_set):\n    with torch.no_grad():\n        n_correct = 0\n        n_samples = 0\n        for i in range(0, len(training_set), batch_size):\n            images_batch = training_set[features][i:i+batch_size]\n            images_batch = torch.from_numpy(np.array(images_batch)).float()\n            labels_batch = training_set.label[i:i+batch_size]\n            labels_batch = torch.from_numpy(np.array(labels_batch))\n            \n         \n            outputs = model(images_batch)\n\n            _, predicted = torch.max(outputs.data, 1)\n            n_samples += labels_batch.size(0)\n            n_correct += (predicted == labels_batch).sum().item()\n\n        acc = 100.0 * n_correct / n_samples\n        print(f'Accuracy of the network on the 10000 test images: {acc} %')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:05:01.142523Z","iopub.execute_input":"2022-02-28T12:05:01.143188Z","iopub.status.idle":"2022-02-28T12:05:01.153055Z","shell.execute_reply.started":"2022-02-28T12:05:01.143149Z","shell.execute_reply":"2022-02-28T12:05:01.152340Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"training_model(data_train, model, epochs, data_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:05:03.497643Z","iopub.execute_input":"2022-02-28T12:05:03.497978Z","iopub.status.idle":"2022-02-28T12:19:53.425167Z","shell.execute_reply.started":"2022-02-28T12:05:03.497942Z","shell.execute_reply":"2022-02-28T12:19:53.423561Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}